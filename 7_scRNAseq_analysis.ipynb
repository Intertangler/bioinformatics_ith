{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Bioinf course 2021 (py3.8)",
      "language": "python",
      "name": "bioinf_course_2021"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "5_scRNAseq_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tlr8bFuYW8qO"
      ],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Intertangler/bioinformatics_stockholm/blob/master/7_scRNAseq_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LwcGeTyW8qD"
      },
      "source": [
        "## Analyzing single-cell RNA-seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf6sYPRlW8qF"
      },
      "source": [
        "single-cell RNA-seq (scRNA-seq) is a technique where individual cells from a sample are separated and unique barcodes are  \n",
        "introduced to label transcripts from different cellular origins. In combination with Next-Generation Sequencing, this allows  \n",
        "the reconstruction of gene expression in complex heterogeneous tissues on the single cell level.  \n",
        "\n",
        "In this computer exercise you will work with an example dataset of scRNA-seq data derived from the developing mouse cortex,  \n",
        "hippocampus and ventricular zone (embryonal day E18.5). Cells were separated and barcoded using the [10X Chromium Controller](https://www.10xgenomics.com/solutions/single-cell/).  \n",
        "In short, individual cells are run through a microfluidic device that deposits individual cells in small oil droplets containing a  \n",
        "bead covered in barcoded cDNA probes. The cells are then lysed and the mRNA they contain hybridizes with the probes, allowing  \n",
        "amplification and the incorporation of the barcodes. Next, the resulting cDNA pool is sequenced and the resulting reads are  \n",
        "separated based on the barcodes they contain.  \n",
        "\n",
        "The primary data processing of the data has already been done and we will do some basic analysis using numpy, scipy and scikitlearn,  \n",
        "very useful packages for any python programmer. There are also many packages to process single-cell data involving complex  \n",
        "mathematics and different layers of data as well as custom file-formats to keep track of it all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMyJePn6W8qF"
      },
      "source": [
        "## Load packages\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import gzip\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import scipy.io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_304Xa2kpI6b"
      },
      "source": [
        "We have saved the data that we will use in the github repository, so we will have to connect that to the collab session with the functions below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF5Us5bplwfA"
      },
      "source": [
        "!git clone https://github.com/Intertangler/bioinformatics_stockholm.git\n",
        "sys.path.insert(0,'/Intertangler/bioinformatics_stockholm.git')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5YGunDkW8qG"
      },
      "source": [
        "We first need to open the data. Currently the data is saved in a folder called 'filtered_feature_bc_matrix'. The folder contains three files:\n",
        "* barcodes.tsv.gz: contains a list of the barcodes that were identified.\n",
        "* features.tsv.gz: contains the gene names and ensemble IDs of the features that were used for alignment.\n",
        "* matrix.mtx.gz: a matrix that contains the count numbers of each feature per barcode. It does not contain any data on the reads or alignments.\n",
        "\n",
        "The data is still compressed in .gz format, but we can decompress it using gzip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viwj42u8W8qG"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzSoXsFaW8qH"
      },
      "source": [
        "We will first need to upload the data to google colab. Run the cell below and upload the 3 files discussed above.  \n",
        "Uploading the matrix can take a while, about a minute or two.\n",
        "After that you can run the cell below it to load it into pyton."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V16DD8FfmXDm"
      },
      "source": [
        "## Load the data matrix\n",
        "matrix_dir = \"bioinformatics_stockholm/filtered_feature_bc_matrix\"\n",
        "mat = scipy.io.mmread(os.path.join(matrix_dir, \"matrix.mtx.gz\"))\n",
        "\n",
        "## Load the gene IDs and gene names from the same file\n",
        "features_path = os.path.join(matrix_dir, \"features.tsv.gz\")\n",
        "feature_ids = [row[0] for row in csv.reader(gzip.open(features_path, mode='rt'), delimiter=\"\\t\")] ## We take the first item of every row\n",
        "gene_names = [row[1] for row in csv.reader(gzip.open(features_path, mode='rt'), delimiter=\"\\t\")] ## We take the second item of every row\n",
        "\n",
        "## Load the barcodes\n",
        "barcodes_path = os.path.join(matrix_dir, \"barcodes.tsv.gz\")\n",
        "barcodes = [row[0] for row in csv.reader(gzip.open(barcodes_path, mode='rt'), delimiter=\"\\t\")]\n",
        "\n",
        "## It's usually a good idea to check that our data structures have the shapes that we expect.\n",
        "## You can use an f-string to print variable inside of string by using curly brackets.\n",
        "print(f'Shape of the dataframe {mat.shape}, there are {len(gene_names)} features and {len(barcodes)} cells')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtOKv7zFW8qI"
      },
      "source": [
        "## Numpy and scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYccXmwiW8qI"
      },
      "source": [
        "In this tutorial we are using two python packages that you might not have encountered yet, but that you will probably be using quite a lot if you continue doing bioinformatics.\n",
        "\n",
        "Ther first is **Numpy** (Numerical python), a package that makes it very easy to work with *n-dimensional arrays*. an array is a data structure that stores data of the same type, as opposed to a list that can contain anything. An **n-dimensional** array is an array with **n** dimensions that contains the same number of values in any direction i.e. a 1-dimensional array is just a list of items of the same data type, a 2-dimensional array is like a table and a 3-dimensional array is like a cube. Numpy allows you to easily manipulate them and do simple computations on them like taking the mean per row, column or whole structure.\n",
        "\n",
        "**Scipy** (Scientific python) is a package that contains all sort of more complicated computations and algorithms for use in scientific or engineering applications. Scipy often uses numpy under the hood and is very well documented and maintained. This package allows you to do very complicated computations without having a lot of experience writing scripts. For instance if you want to do some statistics or linear algebra you can use this package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1pRtMZRW8qI"
      },
      "source": [
        "## Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WU1Wr83W8qJ"
      },
      "source": [
        "You can create a numpy array with the following function:  \n",
        "  \n",
        "**np.array()**  \n",
        "  \n",
        "We imported numpy as np, so np.array tells the interpreter to look for function array in numpy.  \n",
        "This is what a regular (dense) numpy array looks like:  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJD2tGdXW8qJ"
      },
      "source": [
        "np.array([[1, 0, 0, 0],  \n",
        "          [0, 0, 0, 0],  \n",
        "          [1, 0, 0, 0],  \n",
        "          [0, 0, 0, 0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEBXU4I_W8qJ"
      },
      "source": [
        "The matrix we loaded in the previous section is in the form of a \"sparse\" matrix. It is essentially a 2-dimensional array, but stored as a list of non-zero values with the corresponding indices (similar to coordinates). So if you have a lot of zeros in your data (like in scRNA-seq) it is a lot more efficient to store your data like that.\n",
        "\n",
        "The same array we created above would in that case be internally saved like this, where we only remember in what column and row a nonzero value appeared:  \n",
        "(0, 0) 1  \n",
        "(0, 2) 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mag0fWKW8qJ"
      },
      "source": [
        "## Does it make sense to save out data as a sparse matrix?\n",
        "## Let's print some information about our matrix\n",
        "print(f'Total number of positions in the data matrix: {mat.shape[0]*mat.shape[1]}')\n",
        "print(f'Total number of stored positions: {mat.nnz}')\n",
        "print(f'Percentage of elements in the array that is not zero: {(100*mat.nnz)/(mat.shape[0]*mat.shape[1])}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWEjyfTNW8qK"
      },
      "source": [
        "The gene names and cell barcodes are saved as lists, which you have encountered before.  \n",
        "Now that we know how our data is stored we can have a look at how it is distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CepP76sTW8qK"
      },
      "source": [
        "## Quality control"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdRCfiWvW8qK"
      },
      "source": [
        "First we will look at the total number of transcript identified in each cell. In this case those are UMIs (Unique Molecular Identifiers).  \n",
        "We also need to filter out genes that are non-informative. That means genes that are not expressed in enough cells to be reliable for later analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpXmjsqlW8qK"
      },
      "source": [
        "## Total UMIs per cell\n",
        "Total_UMIs = np.array(np.sum(mat, axis=0))[0]\n",
        "\n",
        "## Number of cells expressing feature\n",
        "NCells = np.array(np.sum(mat>0, axis=1))[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bpq7THeW8qL"
      },
      "source": [
        "We can use matplotlib to plot these Quality control measures. If you were to have multiple samples it would be good to plot them separately to check that the data is comparable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvk-nJfvW8qL"
      },
      "source": [
        "## First we make a figure object, this is basically the canvas we will paint our figures on\n",
        "## We'll make it pretty wide because we want to fit two plots next to each other.\n",
        "fig = plt.figure(figsize=(24,6))\n",
        "\n",
        "## Next we add an axis to the figure and plot a histogram in it. We'll add a title as well\n",
        "ax1 = fig.add_subplot(121) ## We have 1 row and 2 columns, this is plot #1\n",
        "ax1.hist(Total_UMIs, alpha=.5, bins=20)\n",
        "ax1.set_title('Total number of UMIs per cell')\n",
        "\n",
        "## We make another axis for the number of cells expressing a gene, but this time we change the last digit in add_subplot to indicate it's a new axis\n",
        "ax2 = fig.add_subplot(122) ## We have 1 row and 2 columns, this is plot #2\n",
        "ax2.hist(NCells, alpha=.5, bins=20)  ## You can change the color, opacity (alpha) and many other things inside this call\n",
        "ax2.set_title('Total number of cells expressing gene')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5caFjmsW8qL"
      },
      "source": [
        "Not the kind of distribution you expected to see right? That's because single-cell data is very sparse remember! Basically it consists mostly of zeros. This makes single-cell analysis a bit tricky, since many analysis methods for bulk RNA-seq assume the data has some kind of continuous distribution (e.g. normally distributed). Luckily we can transform our data to make it fit such expectations and to identify trends. In addition we need to think about how to perform statistics on this kind of data.\n",
        "\n",
        "For now we will perform a logarithmic transformation on our quality control measures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4T7EmNBW8qL"
      },
      "source": [
        "## Total UMIs. We add 1 to every value because we can't divide by zero\n",
        "Total_UMIs_log = np.log10(Total_UMIs + 1)\n",
        "\n",
        "## Number of cells\n",
        "NCells_log = np.log10(NCells + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CefQ5cRCW8qM"
      },
      "source": [
        "We can now plot the transformed distributions, as an example I changed the colors, opacity and number of bins used to plot the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xxlej2aW8qM"
      },
      "source": [
        "## Create a figure with 2 axes showing the log-transformed values\n",
        "\n",
        "## Create a figure\n",
        "fig = plt.figure(figsize=(24,6))\n",
        "\n",
        "## Plot the total UMIs\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.hist(Total_UMIs_log, alpha=.8, bins=30) ## Opacity .8 makes it less see-through than .5\n",
        "ax1.set_title('Log10 UMIs per cell')\n",
        "\n",
        "## Plot the number of cells expressing gene\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.hist(NCells_log, alpha=.5, bins=30, color='#FF0000') ## You can set the color by name or with a hex-code\n",
        "ax2.set_title('Log10 cells expressing gene')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wRmfpVTW8qM"
      },
      "source": [
        "Looks like we do actually have a reasonable distribution! Now we can define some thresholds to filter the data. We should remove cells that have too few or too many UMIs as well as genes that are expressed in very few cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTWofCGiW8qN"
      },
      "source": [
        "min_UMI = 2000\n",
        "max_UMI = 1e5 ## This is the same as 100,000\n",
        "min_cell = 10\n",
        "\n",
        "## Create a figure\n",
        "fig = plt.figure(figsize=(24,6))\n",
        "\n",
        "## Plot the total UMIs\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.hist(Total_UMIs_log, alpha=.8, bins=30)\n",
        "ax1.axvline(np.log10(min_UMI))\n",
        "ax1.axvline(np.log10(max_UMI))\n",
        "ax1.set_title('Total number of UMIs per cell')\n",
        "\n",
        "## Plot the number of cells expressing gene\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.hist(NCells_log, alpha=.5, bins=30, color='#FF0000')\n",
        "ax2.axvline(np.log10(min_cell))\n",
        "ax2.set_title('Total number of cells expressing gene')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCL0YMrKW8qN"
      },
      "source": [
        "Next we can use these thresholds to create a boolean vector (basically the same as binary) to index our data structures. You can use the & operator or np.logical_and() to set a conditional AND for the two values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaFSxS-4W8qN"
      },
      "source": [
        "## Select cells\n",
        "k_x = (Total_UMIs > min_UMI) & (Total_UMIs < max_UMI)\n",
        "\n",
        "## Select features\n",
        "k_y = NCells > min_cell\n",
        "\n",
        "## Filter barcodes and gene names\n",
        "bars = np.array(barcodes)[k_x] ## only retain barcodes that are '1' in k_x\n",
        "genes = np.array(gene_names)[k_y]\n",
        "\n",
        "## Fiter the data\n",
        "data = mat.toarray()[:,k_x] ## Filters cells\n",
        "data = data[k_y,:] ## Filters genes\n",
        "\n",
        "print(f'Cells after filtering: {sum(k_x)}    Genes after filtering: {sum(k_y)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs9FR39tW8qN"
      },
      "source": [
        "Another useful measure is the number of genes expressed in a cell. This of course differs between cell types, but in many cases you can  \n",
        "recognize debris or dead cells by the very low number of genes that are detected for a single barcode. Let's compute this measure next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-40JVelW8qN"
      },
      "source": [
        "## First we calculate the number of genes that are expressed per cell i.e. number of non-zero values\n",
        "NGenes = np.array(np.sum(mat>0, axis=0))[0]\n",
        "NGenes_threshold = 600\n",
        "\n",
        "## Plot the figure\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.scatter(Total_UMIs[k_x], NGenes[k_x],  s=1) ## We only plot the cells we didn't already filter out\n",
        "plt.xlabel('Total UMIs')\n",
        "plt.ylabel('Number of genes expressed in cell')\n",
        "plt.axhline(NGenes_threshold)\n",
        "plt.title('Number of genes vs Total UMI')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78hJzaCqW8qN"
      },
      "source": [
        "Seems like we detected some more outliers here. Let's filter them out as well by thresholding on NGenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aViSOiEDW8qO"
      },
      "source": [
        "## Select cells\n",
        "k_x = (Total_UMIs > min_UMI) & (Total_UMIs < max_UMI) & (NGenes > NGenes_threshold)\n",
        "\n",
        "## Filter the barcodes and cells\n",
        "bars = np.array(barcodes)[k_x]\n",
        "data = mat.toarray()[:,k_x] ## Filters cells\n",
        "\n",
        "## Select features. First recompute NCells without the removed cells\n",
        "NCells = np.array(np.sum(data>0, axis=1))\n",
        "k_y = NCells > min_cell\n",
        "\n",
        "## Filter gene names and genes\n",
        "genes = np.array(gene_names)[k_y]\n",
        "data = data[k_y,:] ## Filters genes\n",
        "\n",
        "print(f'Cells after filtering: {sum(k_x)}    Genes after filtering: {sum(k_y)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlr8bFuYW8qO"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8wHBTaW8qO"
      },
      "source": [
        "Next we need to normalize the data. That means we need to account for variance that derives from the capture effiency not being stable across samples. Some cells in our dataset have more transcripts while others have less, but that might not mean this was also the case before we measured them. For now we will assume that all cells had the same number of transcripts before we took our measurements. We will thus compare the ratios of present genes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtaqwCAcW8qO"
      },
      "source": [
        "## First, we will determine the library size per cell. This is the same as total UMIs, so we can just filter the \n",
        "## Total_UMIs array we generated before so we only have the cells.\n",
        "lib_size = Total_UMIs[k_x]\n",
        "\n",
        "## Next we calculate the median library size since we'll normalize our data to that level\n",
        "med_lib = np.median(lib_size)\n",
        "\n",
        "print(f'Median library size {med_lib}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19hw2ijeW8qO"
      },
      "source": [
        "Next we can divide each column by the appropriate library size and multiply every value by the median library size. The result is that each column sums to the same value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCwrc-K9W8qO"
      },
      "source": [
        "data = (data / lib_size) * med_lib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "206w-hlLW8qP"
      },
      "source": [
        "We don`t want downstream analysis to be biased towards highly expressed genes, so we are going to down weigh them. You can do this by for instance taking the square-root or log transforming them like we showed earlier. Log-transforming is the most common method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSy2H50IW8qP"
      },
      "source": [
        "norm = np.log(data+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U8WE6n8W8qP"
      },
      "source": [
        "## Dimensional Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOsGUwbTW8qP"
      },
      "source": [
        "Next we're going to try and visualize the differences between cells by plotting them in low dimensional space. Unfortunately, the cells exist in high-dimensional space *i.e.* they have many different features (genes) and we can't exactly look at all of them at the same time. We thus need to 'simplify' the data and embed the cells in low-dimensional space. This can be done using methods like Principal Component Analysis (PCA) and t-Stochastic Neighbour Embedding (tSNE). These methods try to explain as much variance as possible across features, summarizing many features into a limited number of components and then ordering cells along them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMkG8YADW8qP"
      },
      "source": [
        "Before we can do the PCA we need to select which features we will use. A lot of genes don't really change their expression between cell types, these are so called 'house keeper' genes. They are often involved in processes that all cells require like maintaining the Actin skeleton. We will thus look for genes that have **high variance**. To do this we will however need to control for **mean expression** since highly expressed genes tend to have higher variance.\n",
        "\n",
        "In the code block below we train a simple machine learning model, the Support Vector Machine. You don't need to know the details about how that works, the important thing is that we model the relationship between variance and mean and we eventually select the 2,000 genes that have the strongest divergence of their variance from their mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUmmiNbiW8qP"
      },
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "N_features = 2000\n",
        "\n",
        "mu = np.mean(data, axis=1)\n",
        "s = np.std(data, axis=1)\n",
        "cv = s/mu\n",
        "\n",
        "log2_m = np.log2(mu)\n",
        "log2_cv = np.log2(cv)\n",
        "\n",
        "clf = LinearSVR(tol=1e-5, max_iter=20000)\n",
        "clf.fit(log2_m[:, np.newaxis], log2_cv)\n",
        "fitted_fun = clf.predict\n",
        "\n",
        "# Score is the relative position with respect of the fitted curve\n",
        "score = log2_cv - fitted_fun(log2_m[:, np.newaxis])\n",
        "idx = np.fromiter(range(data.shape[0]), int)[np.argsort(score)][-2000:]\n",
        "selected = np.zeros(data.shape[0], dtype=bool)\n",
        "selected[np.sort(idx)] = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAN1vgRIW8qP"
      },
      "source": [
        "## Let's plot the results\n",
        "plt.scatter(np.log2(mu), np.log2(cv), s=1)\n",
        "plt.scatter(np.log2(mu[selected]), np.log2(cv[selected]), s=1, c='red')\n",
        "plt.xlabel('log2(mean expression)')\n",
        "plt.ylabel('log2(Coefficient of Variance)')\n",
        "# plt.axhline(q)\n",
        "plt.title('Variance and mean expression of features')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp0Kqgn8W8qQ"
      },
      "source": [
        "Now we simplify the data using PCA. We will generate 20 components, which will simplify downstream analysis. The function to calculate PCs can be imported from [Scikit-learn](https://scikit-learn.org/stable/), a very powerful, free to use machine-learning library that is included in every anaconda installation.\n",
        "\n",
        "For the PCA we will use the log-scaled data, since we don't want highly expressed genes to dominate our PCA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL2er9RiW8qQ"
      },
      "source": [
        "## First we setup the PCA object and we fit our normalized data to it.\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "PCs = PCA(n_components=20)\n",
        "PCs.fit(norm[selected,:])\n",
        "print(f'Shape of the reduced dataframe {PCs.components_.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLXckeOBW8qQ"
      },
      "source": [
        "You should always try to have a look at the resulting components to see if they are informative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffIGHfqmW8qQ"
      },
      "source": [
        "## Let's plot the first few components\n",
        "fig, ax = plt.subplots(nrows = 4, ncols = 3, figsize=(24,24))\n",
        "\n",
        "y = -1\n",
        "x = 0\n",
        "for k in range(10):\n",
        "    x = k%3\n",
        "    if x == 0: ## True in first round\n",
        "        y += 1    \n",
        "\n",
        "    ax[y,x].scatter(PCs.components_[(2*k),:], PCs.components_[(2*k+1),:], s=1)\n",
        "    ax[y,x].set_title(f'Component {2*k} vs Component {2*k+1}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puXJMsEnW8qQ"
      },
      "source": [
        "Clearly the first few components are the most informative and from component 8 onwards you see more of a gaussian-like distribution, which indicate they capture mostly noise. Similarly we can plot the cumulative variance explained by each component and you will see that the plot start to reach an plateau around that point. The last few components do explain some variance, but they are less clear so it's better to exclude them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_5vne7RW8qQ"
      },
      "source": [
        "ncomp=8\n",
        "\n",
        "plt.plot(np.cumsum(PCs.explained_variance_ratio_), alpha=.5)\n",
        "plt.title(f'Cumulative explained variance by component')\n",
        "plt.axvline(ncomp, color='red', alpha=.5)\n",
        "plt.xticks(np.arange(0, 20, 2));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QR7fanDW8qQ"
      },
      "source": [
        "#### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_sPpoq0W8qQ"
      },
      "source": [
        "Next we're going to perform t-Stochastic Neighbour Embedding (tSNE). The mathematics behind tSNE are quite complex and not very intuitive, however the result makes interpreting  \n",
        "data actually a lot more intuitive! Briefly said, tSNE aims to represent similaries between points that exist in high dimensional space (for instance tens of thousands of genes)  \n",
        "by projecting these points onto a 2-dimensional (or 3-D) plane. Points that are similar to each other will be placed near each other. However, distance is not a measure for  \n",
        "dissimilarity here since long distances are warped *i.e.* only local structure is preserved. Take the image below as an example. You can unfold it from 3D to 2D while still preserving  \n",
        "the structure of cells. So we 'unfold' our data so to speak.\n",
        "\n",
        "![swiss roll](https://bioinformatics-training.github.io/intro-machine-learning-2017/images/swiss_roll_manifold_sculpting.png)\n",
        "\n",
        "To get a better sense of what is going on have a look at [this website](https://distill.pub/2016/misread-tsne/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0X259CLW8qR"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "TSNE = TSNE(init='pca', random_state=1) ## TSNE uses a random seed to initiate, meaning that the results don't always look the same!\n",
        "TSNE.fit(PCs.components_[:ncomp,:].T)\n",
        "print(f'We now have a {TSNE.embedding_.shape} dataframe that we can use to plot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTc9YBrAW8qR"
      },
      "source": [
        "Notice that we set a 'random state' (also called a seed), this is a number that the algorithm needs to initialize i.e. where to start from. If you change this the results will also change! It is often a good idea to set a random state to a fixed number to keep results more consistent.\n",
        "\n",
        "The resulting 2D projection can be plotted to give a sense of the distribution of the cells. What do you think? Can you see any groups in this data that are probably different from each other?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "443MHizXW8qR"
      },
      "source": [
        "fig = plt.figure(figsize=(12,8))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.scatter(TSNE.embedding_[:,0], TSNE.embedding_[:,1], alpha=.5)\n",
        "ax.set_title('tSNE of mouse cortex, hippocampus and ventricular zone cells (E18.5)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v3-BX7CW8qR"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GXLnkcBW8qR"
      },
      "source": [
        "Whe now have a visual representation of the structure of our data, but we haven't quite divided our data in different groups of cells yet. This process of statisticially dividing the data into meaningful  \n",
        "groups is usually referred to as 'clustering' and can be performed in many different ways. Currently graph-based methods are very popular, but depending on your data, how much you already know about  \n",
        "the cells and what questions you have there are many different methods you can apply. We will demonstrate one simple method that is included in the scikit-learn library and is very easy to apply."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvvXdeg7W8qR"
      },
      "source": [
        "We will cluster our data using Spectral Clustering. This is a form of graph-based clustering where you first build a graph of cells based on the eigenvalues (spectrum) of their similarity matrix and then try  \n",
        "to cut that graph into groups to identify the different clusters. The assumption is that similar data points form communities that are difficult to separate. A downside here is that we need to define  \n",
        "a number of clusters that we wish to identify. There are however also community detection alghoritms that don't require a set number of cluster (for instance the Leiden or Louvain methods)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0stUGLCpW8qR"
      },
      "source": [
        "from sklearn.cluster import SpectralClustering\n",
        "\n",
        "Spectral = SpectralClustering(n_clusters=10, n_neighbors=20, random_state = 1)\n",
        "Spectral.fit(PCs.components_[:ncomp,:].T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qfqUmRDW8qS"
      },
      "source": [
        "We can plot the cluster labels as colors in our tSNE to see if the separation makes sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJHuVJ2ZW8qS"
      },
      "source": [
        "fig = plt.figure(figsize=(12,8))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.scatter(TSNE.embedding_[:,0], TSNE.embedding_[:,1], c = Spectral.labels_, cmap= 'Spectral', alpha=.5)\n",
        "ax.set_title('Spectral clustering')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6Z1yVndW8qS"
      },
      "source": [
        "Try to change some of the clustering parameters and look at the results. They change quite a bit and you can imagine it's important to be aware of what values you use to do your clustering.\n",
        "\n",
        "Different clustering methods yield different results because they take different parts of the underlying structure of the data into account. In addition there are often multiple parameters to take into account, which also influence the clustering results. It is often wise to try multiple different methods and to compare results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q23bfS-ZW8qS"
      },
      "source": [
        "## Cell type markers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn0PCmJ2W8qS"
      },
      "source": [
        "Now we have clusters, but we don't know what any of them actually are. Let's plot the expression of some markers to see what our clusters correspond to.  \n",
        "*Tnc* is a marker for proliferation, *i.e.* these are dividing cells. *Top2a* is another cell cycle gene (S/G2).  *Eomes* is a marker for Neuroblasts.  \n",
        "These are cells that are committed to a neuronal fate, but are still maturing and migrating to their final positions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYeuhU7kW8qS"
      },
      "source": [
        "## Let's plot the expression of some markers we would expect to see\n",
        "\n",
        "fig, ax = plt.subplots(nrows = 3, ncols = 3, figsize=(18,18))\n",
        "markers = ['Tnc','Top2a', 'Eomes',  \n",
        "           'Gad2', 'Lhx6', 'Htr3a', \n",
        "           'Neurod2', 'Bcl11b', 'Satb2']\n",
        "\n",
        "y = -1\n",
        "x = 0\n",
        "for k in range(len(markers)):\n",
        "    marker = markers[k]\n",
        "    x = k%3\n",
        "    if x == 0:\n",
        "        y += 1    \n",
        "\n",
        "    c = norm[genes == marker,:][0]\n",
        "        \n",
        "    ax[y,x].scatter(TSNE.embedding_[:,0], TSNE.embedding_[:,1], color = 'lightgray')\n",
        "    ax[y,x].scatter(TSNE.embedding_[c>0,0], TSNE.embedding_[c>0,1], c = c[c>0], cmap = 'viridis')\n",
        "    ax[y,x].set_title(f'{marker}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp14mvx8W8qS"
      },
      "source": [
        "**Exercise** Explain what these markers indicate. What are the major cell types here? Use [this](http://mousebrain.org/genesearch.html) cell type atlas to figure out what the different populations are. Why do some markers span across clusters and are other confined to one population (*Gad2*/*Lhx6*)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovEU6iqQW8qS"
      },
      "source": [
        "# Take home assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu9_R8YSW8qT"
      },
      "source": [
        "Submit your assignments as a word document or pdf and include problem numbers along with your answers/images/printouts etc. Attach your raw code to your report. You will be graded first on getting the correct answer/producing the plot or image to each problem. In the event that you get the answer wrong, partial credit can be received if you leave comments (using the # sign) in your code to explain what your program is doing at each step. Include at comments on at least 50% of lines of your code to receive this credit. Comments should explain what each line is doing in the program context - not just what it does in isolation. As a test, if the comment were taken alone, would it still tell you something about the rest of the program, or would it merely tell you what can literally be deduced from reading the code itself on that line. Comments should also be concise since the goal is to make the code easier to understand, not burdensome. E.g.:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGQj1fKjW8qT"
      },
      "source": [
        "# for i in my_list: #loop through each item in order to update the sum\n",
        "#     sum = sum + i #update the sum with item i from my_list\n",
        "#     If sum > threshold: #check if sum exceeds the threshold\n",
        "#         threshold_exceeded = True #update status of threshold check"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6PuHGs_W8qT"
      },
      "source": [
        "If you get stuck, remember that it is ok to google for ideas or troubleshooting. Many examples exist online that can help you accomplish parts of the problem. Outside of thiscourse, you will often need to quickly accomplish complex programming tasks, and skillfully utilizing online resources is an important habit to develop. Where it is warranted, give credit to the sources you obtain code from by citing them with comments in the code.  \n",
        "\n",
        "The following excercises are designed to be completed after the 'scRNA-seq' computer excercises. The problems require you to load the cluster labels, gene names and the normalized data. You can either rerun your script and add the solutions to the two problems at the end (just make sure to send in only the assignments and not the whole script) or you can save your results from that script using the line below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBLK7Ac7W8qT"
      },
      "source": [
        "## Problem 1: Gene expression Box-plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOtLmjbhW8qT"
      },
      "source": [
        "While it can be very useful to show expression levels of genes on a tsne-plot to show cluster relationships and general enrichments, sometimes you want to more explicitly look at level differences. For this reason it can be better to use a boxplot or violin plot. Let's plot the expression of *Gad2*, an important interneuron marker that we also looked at in the excersises, but this time in a boxplot. For this you will need to load the numpy module and the matplotlib module.\n",
        "\n",
        "It is convention to plot the log normalized data in these kind of plots since you can read them very intuitively. \n",
        "After normalizing the data you need to do the following things:\n",
        "\n",
        "* Create a figure and axis object. Give the figure a width of 12 and height of 8\n",
        "* Select the row correspondig to the correct gene.\n",
        "* Split the row into seperate vectors by indexing using the cluster labels.\n",
        "* Use the box fuction in matplotlib.pyplot to plot the expression (boxes). Show outliers as '+'.\n",
        "* Set the title and y-axis description.\n",
        "\n",
        "Replace the '''####''' statements to finish the exercise.\n",
        "Also finish the code annotations (Text behind the two hashtags (##)) by explaining clearly what the line of code does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFXNxlFQW8qT"
      },
      "source": [
        "import matplotlib.cm as cm  ## We import the colormap module from matplotlib\n",
        "\n",
        "## \n",
        "g = 'Gad2'\n",
        "\n",
        "## \n",
        "fig = '''####'''\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "## \n",
        "boxes = []\n",
        "n_labels = len(np.unique(Spectral.labels_))\n",
        "\n",
        "## \n",
        "for x in range('''####'''):\n",
        "    boxes.append(norm['''####''', Spectral.labels_ == '''####'''])\n",
        "\n",
        "## \n",
        "bplot = ax.boxplot('''####''', labels = range('''####'''), sym='''####''', patch_artist=True)\n",
        "\n",
        "## \n",
        "ax.set_title(f'{'''####'''} expression')\n",
        "ax.set_ylabel('''####''')\n",
        "\n",
        "# \n",
        "cmap = cm.ScalarMappable(cmap='Spectral')\n",
        "unique_labels = range(n_labels)\n",
        "for patch, color in zip(bplot['boxes'], cmap.to_rgba(unique_labels)):\n",
        "    patch.set_facecolor('''####''')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB86SwDGW8qT"
      },
      "source": [
        "## Problem 2: Mitochondrial Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pTjV36zW8qT"
      },
      "source": [
        "The mitochondrial content of a cell is often used as a quality measure. While some particular cell types tend to have slightly higher mitochondrial content, very high levels are usually an indicator of high cellular stress. We usually filter these cells from the data as these cells are often dead and not representative of 'healthy' tissue.\n",
        "\n",
        "* Plot the summed mitochondrial content (normalized against the total UMI) of each cell in a histogram. \n",
        "* Use the unnormalized matrix  and the corresponding gene_names list\n",
        "\n",
        "**Hint** The names of mitochondrial genes in most annotations start with 'mt-'. You get them with the following function: \n",
        "* list(filter(lambda x: 'mt-' in x, gene_names))\n",
        "\n",
        "Replace the '''####''' statements to finish the exercise.\n",
        "Also finish the code annotations (Text behind the two hashtags (##)) by explaining clearly what the line of code does."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gv-b-28W8qU"
      },
      "source": [
        "## \n",
        "mito = '''####'''\n",
        "\n",
        "## \n",
        "k = [x in '''####''' for x in '''####''']\n",
        "\n",
        "## \n",
        "mito_content = np.sum('''####'''.toarray()[k,:], axis='''####''') / '''####'''\n",
        "\n",
        "## \n",
        "plt.figure(figsize=(12,6))\n",
        "plt.hist('''####''', alpha=.5, bins=30)\n",
        "plt.title('Mitochondrial content')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}